"""Conversational financial advisor interface."""

from __future__ import annotations

from typing import List

import streamlit as st

from modules.chat_manager import ChatManager
from utils.session import (
    get_chat_history,
    get_i18n,
    get_monthly_budget,
    set_chat_history,
)


def _init_session_defaults() -> None:
    st.session_state.setdefault("chat_history", [])
    st.session_state.setdefault("chat_cache", {})


def render() -> None:
    """Render chat UI backed by ChatManager and GPT-4o."""
    i18n = get_i18n()
    st.title(i18n.t("chat.title"))
    st.write(i18n.t("chat.subtitle"))

    _init_session_defaults()
    history: List[dict] = get_chat_history()
    transactions = st.session_state.get("transactions", [])

    current_budget = get_monthly_budget()

    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„budgetï¼ˆæç¤ºå¯åœ¨ä¾§è¾¹æ ä¿®æ”¹ï¼‰
    # Display current budget (hint: can be changed in sidebar)
    st.info(f"ðŸ’° {i18n.t('chat.current_budget_info', budget=f'Â¥{current_budget:,.0f}')}")

    # ç¤ºä¾‹é—®é¢˜ï¼ˆçŽ°åœ¨å å…¨å®½ï¼‰(Sample questions - now full width)
    st.markdown(
        "\n".join(
            [
                f"**{i18n.t('chat.sample_title')}**",
                f"- {i18n.t('chat.sample_q1')}",
                f"- {i18n.t('chat.sample_q2')}",
                f"- {i18n.t('chat.sample_q3')}",
                f"- {i18n.t('chat.sample_q4')}",
            ]
        )
    )

    chat_manager = ChatManager(
        history=history,
        transactions=transactions,
        monthly_budget=current_budget,
        locale=st.session_state.get("locale", "zh_CN"),
    )
    chat_manager.update_transactions(transactions)
    chat_manager.set_monthly_budget(current_budget)

    if history:
        for message in history:
            with st.chat_message(message["role"]):
                st.write(message["content"])
    else:
        st.info(i18n.t("chat.empty_history"))

    user_prompt = st.chat_input(i18n.t("chat.input_placeholder"))
    if not user_prompt:
        return

    history.append({"role": "user", "content": user_prompt})
    history = set_chat_history(history)
    with st.chat_message("user"):
        st.write(user_prompt)

    cache: dict = st.session_state["chat_cache"]
    if user_prompt in cache:
        cached_reply = cache[user_prompt]
        history.append({"role": "assistant", "content": cached_reply})
        history = set_chat_history(history)
        with st.chat_message("assistant"):
            st.write(cached_reply)
            st.caption(i18n.t("common.cache_hit"))
        return

    with st.chat_message("assistant"):
        with st.spinner(i18n.t("common.loading_thinking")):
            response = chat_manager.generate_response(user_prompt)
            cache[user_prompt] = response
            if len(cache) > 20:
                first_key = next(iter(cache))
                cache.pop(first_key, None)
            st.write(response)
    history.append({"role": "assistant", "content": response})
    set_chat_history(history)


if __name__ == "__main__":  # pragma: no cover - streamlit entry point
    render()
